{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b724ca99-3624-4e31-a67a-d2b7694c6472",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "696d1d5b-b816-4212-8d26-9a199e635bdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "num = spark.range(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16bfa261-81f5-44ab-b729-82b98572a035",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered = num.filter(col(\"id\") >2)\n",
    "filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f175456-8e9a-42af-af0b-b7840fab14a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Color</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16087</th>\n",
       "      <td>WA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45060</th>\n",
       "      <td>TX</td>\n",
       "      <td>Green</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29724</th>\n",
       "      <td>CO</td>\n",
       "      <td>Brown</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74586</th>\n",
       "      <td>AZ</td>\n",
       "      <td>Brown</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>NV</td>\n",
       "      <td>Red</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State  Color  Count\n",
       "16087    WA   Blue     79\n",
       "45060    TX  Green     49\n",
       "29724    CO  Brown     69\n",
       "74586    AZ  Brown     65\n",
       "135      NV    Red     94"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Workspace/Users/digicomstarter43@gmail.com/mnm_dataset.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7eabe8b0-97d0-4241-8f1d-fece66ab416b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build a SparkSession using the SparkSession APIs.\n",
    "# If one does not exist, then create an instance. There\n",
    "# can only be one SparkSession per JVM\n",
    "spark = (SparkSession \n",
    "         .builder\n",
    "         .appName(\"PythonMnMCount\")\n",
    "         .getOrCreate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d79ca26-4659-44ac-80ef-9cd023f7f5b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mnm_df = (spark.read.format(\"csv\")\n",
    "          .option(\"header\",\"true\")\n",
    "          .option(\"inferSchema\",\"true\")\n",
    "          .load(\"/Workspace/Users/digicomstarter43@gmail.com/mnm_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "309aaffb-d0e8-432e-96ce-98d44feeacf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State|Color |Total|\n",
      "+-----+------+-----+\n",
      "|CA   |Yellow|1807 |\n",
      "|WA   |Green |1779 |\n",
      "|OR   |Orange|1743 |\n",
      "|TX   |Green |1737 |\n",
      "|TX   |Red   |1725 |\n",
      "|CA   |Green |1723 |\n",
      "|CO   |Yellow|1721 |\n",
      "|CA   |Brown |1718 |\n",
      "|CO   |Green |1713 |\n",
      "|NV   |Orange|1712 |\n",
      "|TX   |Yellow|1703 |\n",
      "|NV   |Green |1698 |\n",
      "|AZ   |Brown |1698 |\n",
      "|CO   |Blue  |1695 |\n",
      "|WY   |Green |1695 |\n",
      "|NM   |Red   |1690 |\n",
      "|AZ   |Orange|1689 |\n",
      "|NM   |Yellow|1688 |\n",
      "|NM   |Brown |1687 |\n",
      "|UT   |Orange|1684 |\n",
      "|NM   |Green |1682 |\n",
      "|UT   |Red   |1680 |\n",
      "|AZ   |Green |1676 |\n",
      "|NV   |Yellow|1675 |\n",
      "|NV   |Blue  |1673 |\n",
      "|WA   |Red   |1671 |\n",
      "|WY   |Red   |1670 |\n",
      "|WA   |Brown |1669 |\n",
      "|NM   |Orange|1665 |\n",
      "|WY   |Blue  |1664 |\n",
      "|WA   |Yellow|1663 |\n",
      "|WA   |Orange|1658 |\n",
      "|CA   |Orange|1657 |\n",
      "|NV   |Brown |1657 |\n",
      "|CA   |Red   |1656 |\n",
      "|CO   |Brown |1656 |\n",
      "|UT   |Blue  |1655 |\n",
      "|AZ   |Yellow|1654 |\n",
      "|TX   |Orange|1652 |\n",
      "|AZ   |Red   |1648 |\n",
      "|OR   |Blue  |1646 |\n",
      "|OR   |Red   |1645 |\n",
      "|UT   |Yellow|1645 |\n",
      "|CO   |Orange|1642 |\n",
      "|TX   |Brown |1641 |\n",
      "|NM   |Blue  |1638 |\n",
      "|AZ   |Blue  |1636 |\n",
      "|OR   |Green |1634 |\n",
      "|UT   |Brown |1631 |\n",
      "|WY   |Yellow|1626 |\n",
      "|WA   |Blue  |1625 |\n",
      "|CO   |Red   |1624 |\n",
      "|OR   |Brown |1621 |\n",
      "|OR   |Yellow|1614 |\n",
      "|TX   |Blue  |1614 |\n",
      "|NV   |Red   |1610 |\n",
      "|CA   |Blue  |1603 |\n",
      "|WY   |Orange|1595 |\n",
      "|UT   |Green |1591 |\n",
      "|WY   |Brown |1532 |\n",
      "+-----+------+-----+\n",
      "\n",
      "Total Rows 60\n"
     ]
    }
   ],
   "source": [
    "# We use the DataFrame high-level APIs. Note\n",
    "# that we don't use RDDs at all. Because some of Spark's\n",
    "# functions return the same object, we can chain function calls.\n",
    "# 1. Select from the DataFrame the fields \"State\", \"Color\", and \"Count\"\n",
    "# 2. Since we want to group each state and its M&M color count,\n",
    "# we use groupBy()\n",
    "# 3. Aggregate counts of all colors and groupBy() State and Color\n",
    "# 4 orderBy() in descending order\n",
    "\n",
    "# In Databrick, We are getting an error which running actions on the spark dataframe read by spark directly from csv file\n",
    "# So We read file with pandas and converted pandas dataframe in Spark dataframe\n",
    "\n",
    "mnm_df = spark.createDataFrame(df)\n",
    "count_mnm_df = (mnm_df\n",
    "                .select(\"State\",\"Color\",\"Count\")\n",
    "                .groupBy(\"State\",\"Color\")\n",
    "                .agg(count(\"Count\").alias(\"Total\"))\n",
    "                .orderBy(\"Total\", ascending=False))\n",
    "count_mnm_df.show(n=60, truncate=False)\n",
    "print(f\"Total Rows {count_mnm_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7358993-73cc-4b52-b093-4663abedbffc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State|Color |Total|\n",
      "+-----+------+-----+\n",
      "|CA   |Yellow|1807 |\n",
      "|CA   |Green |1723 |\n",
      "|CA   |Brown |1718 |\n",
      "|CA   |Orange|1657 |\n",
      "|CA   |Red   |1656 |\n",
      "|CA   |Blue  |1603 |\n",
      "+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_mnm_df.select(\"State\",\"Color\",\"Total\").where(col(\"State\") == \"CA\").show(n=10, truncate=False) # For a custom state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bc4d255-31f8-42ea-87c9-99956345ff87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.stop() # Stop the SparkSession"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pyspark-ch1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
